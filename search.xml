<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[AllenNLP基础]]></title>
    <url>%2F2018%2F12%2F20%2FAllenNLP%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[安装pipenv install allennlp 启动allennlp 出现错误 ModuleNotFoundError: No module named ‘_sqlite3’ 解决方案，编译安装python： yum install sqlite-devel cd python-3.6.1 ./configure make make install 然后import sqlite3无错。]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS系统-python安装libsvm]]></title>
    <url>%2F2018%2F12%2F20%2FCentOS%E7%B3%BB%E7%BB%9F-python%E5%AE%89%E8%A3%85libsvm%2F</url>
    <content type="text"><![CDATA[基本步骤，（如果安装在系统的python中）下载libsvm，地址http://www.csie.ntu.edu.tw/~cjlin/libsvm/解压解压方法 https://sayarara.github.io/2018/11/26/linux常用命令清单/ tar -xzf libsvm-3.23.tar.gz cd 进入libsvm-3.23文件夹，然后makecd libsvm-3.23 make cd 进入libsvm的python子文件夹 /libsvm-3.23/pythoncd python make 拷贝编译好的文件将该python文件夹下的.py 文件拷贝到系统python的site-packages中，将其上一级目录中的libsvm.so.2拷贝到系统python中 $ sudo cp *.py /usr/lib/python2.7/site-packages/ $ cd .. $ sudo cp libsvm.so.2 /usr/lib/python2.7/ 检查是否安装成功新开一个terminal，进入python import svm import svmutil 如果安装在虚拟环境中（比如pipenv）同基本步骤，但是将编译好的.py文件和libsvm.so.2文件拷贝到虚拟环境路径下 获得虚拟环境路径(testpipenv3) [root@VM_32_16_centos testpipenv3]# pipenv --venv /root/.local/share/virtualenvs/testpipenv3-gvhz0M9a 拷贝$ sudo cp *.py /root/.local/share/virtualenvs/testpipenv3-gvhz0M9a/lib/python3.6/site-packages $ cd .. $ sudo cp libsvm.so.2 /root/.local/share/virtualenvs/testpipenv3-gvhz0M9a/lib/python3.6/]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[待学习清单]]></title>
    <url>%2F2018%2F12%2F18%2F%E5%BE%85%E5%AD%A6%E4%B9%A0%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[Rust. 用Rust来优化Python性能。 vue.js 或者react替换django前端 AllenNLP paper list多人编辑 解决一致性问题的CRDT模型 （自主性，零共识自动解决冲突） High Responsiveness for Group Editing CRDTs https://pages.lip6.fr/Marc.Shapiro/papers/rgasplit-group2016-11.pdf CRDT——解决最终一致问题的利器 https://yq.aliyun.com/articles/635632?utm_content=m_1000015503 serverless zappa https://github.com/Miserlou/Zappa#using-a-local-repo]]></content>
      <categories>
        <category>notes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[条件随机场CRF]]></title>
    <url>%2F2018%2F12%2F17%2F%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF%2F</url>
    <content type="text"><![CDATA[CRF（条件随机场，Conditional Random Field） 用简单的语言理解CRF https://www.sohu.com/a/207085690_206784 以例子的方式来说明CRF https://www.imooc.com/article/27795 详细的阐述 https://zhuanlan.zhihu.com/P/28465510 An Introduction to Conditional Random Fields http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf]]></content>
      <categories>
        <category>notes.algorithm</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[系统评估]]></title>
    <url>%2F2018%2F12%2F13%2F%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%2F</url>
    <content type="text"><![CDATA[RAIL performance modelSystem should feel lightweight and responsive. 用于保证人机交互的友好性。 RAIL 模型 https://developers.google.com/web/fundamentals/performance/rail一种以用户为中心的性能模型 RAIL 步骤 关键指标 用户操作 响应 response 输入延迟时间（从点按到绘制）小于 100 毫秒。 用户点按按钮（例如打开导航） 动画 animation 每个帧的工作（从 JS 到绘制）完成时间小于 16 毫秒。 用户滚动页面，拖动手指（例如，打开菜单）或看到动画。 拖动时，应用的响应与手指位置有关（例如，拉动刷新、滑动轮播）。 此指标仅适用于拖动的持续阶段，不适用于开始阶段。 空闲 idle 主线程 JS 工作分成不大于 50 毫秒的块 用户没有与页面交互，但主线程应足够用于处理下一个用户输入。2 加载 load 页面可以在 1000 毫秒内就绪。 用户加载页面并看到关键路径内容。 Chrome DevToolsPerformance (原Timeline)和 Memory (原Profile)工具用于记录用户操作和分析性能。 Chrome DevTools 使用详解: https://segmentfault.com/a/1190000007877846 Chrome DevTools（Chrome 开发者工具） 是内嵌在 Chrome 浏览器里的一组用于网页制作和调试的工具。Chrome 金丝雀版本（Chrome Canary）可以获得最新版本的 DevTools 访问 DevTools 选择右上角Chrome 菜单，然后选择更多工具 -&gt; 开发者工具 右键，选择检查/审查元素 快捷键打开： Ctrl + Shift + I, F12 / Cmd + Opt + I，打开 DevTools Ctrl + Shift + J / Cmd + Opt + J，打开 DevTools，并且定位到控制台面板 Ctrl + Shift + C / Cmd + Opt + C，打开 DevTools，并且开启审查元素模式（相当于点击了 DevTools 左上角的图标） 其他常用快捷键： F5, Ctrl + R / Cmd + R，刷新页面 Ctrl + F5, Ctrl + Shift + R / Cmd + Shift + R，刷新页面并忽略缓存 Ctrl + ‘+’ / Cmd + Shift + ‘+’，放大 DevTools Ctrl + ‘-‘ / Cmd + Shift + ‘-‘，缩小 DevTools Ctrl + 0 / Cmd + 0，DevTools 恢复大小 涉及太多前端，放弃使用。]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>CHI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python常见错误]]></title>
    <url>%2F2018%2F12%2F12%2FPython%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[18个新手常见Python运行时错误 https://blog.csdn.net/newtonnl/article/details/70792289 SyntaxError: invalid syntax 括号没有成对出现，会导致下一行代码中提示出现该错误 忘记在 if , elif , else , for , while , class ,def 声明末尾添加 ：]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SourceTree使用基础]]></title>
    <url>%2F2018%2F12%2F12%2FSourceTree%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[安装及配置参考windows系统配置指南 push本地代码至远程仓库 拖动文件到本地目标文件夹 拖动本地修改文件至已暂存 添加本地修改记录，提交至本地仓库 push（点击推送）到远程仓库]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python字典value查key]]></title>
    <url>%2F2018%2F12%2F11%2Fpython%E5%AD%97%E5%85%B8value%E6%9F%A5key%2F</url>
    <content type="text"><![CDATA[key查valuedict [&#39;key&#39;] value查key确保value值distinct 12345678910111213#法1def get_key1 (dict, value): return [k for k, v in dict.items() if v == value] #法2def get_key2 (dict, value): return list (dict.keys()) [list (dict.values()).index (value)] #法3: 反转原字典，由原来的K-V存储形式，变为V-K存储形式def get_key3 (dict, value): new_dict = &#123;v : k for k, v in dict.items()&#125; return new_dict[value]]]></content>
      <categories>
        <category>notes.code</category>
      </categories>
      <tags>
        <tag>dict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch基础]]></title>
    <url>%2F2018%2F12%2F03%2FPyTorch%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[与Tensorflow的静态计算图不同，pytorch的计算图是动态的，可以根据计算需要实时改变计算图基于python，具备GPU加速的张量和动态神经网络深度学习框架。 安装按照官网指示，https://pytorch.org python 3.6 cpu 稳定版 pip3 install http://download.pytorch.org/whl/cpu/torch-0.4.1-cp36-cp36m-linux_x86_64.whl pip3 install torchvision —可以换个有gpu的服务器么。。。 教程官方教程 初级教程，通俗易懂 https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html#sphx-glr-beginner-nlp-pytorch-tutorial-py Pytorch张量运算100多种，包括转置，数学运算，线性代数，索引切分 https://pytorch.org/docs/stable/torch.html Tensor创建：1234567891011121314151617181920212223242526# torch.tensor(data) creates a torch.Tensor object with the given data.# 1D tensor: vectorV_data = [1., 2., 3.]V = torch.tensor(V_data)# Creates a matrix# 2D tensor 矩阵M_data = [[1., 2., 3.], [4., 5., 6]]M = torch.tensor(M_data)# Create a 3D tensor of size 2x2x2.# 3D tensorT_data = [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]]T = torch.tensor(T_data)# Index into V and get a scalar (0 dimensional tensor)print(V[0])# Get a Python number from itprint(V[0].item())# Index into M and get a vectorprint(M[0])# Index into T and get a matrixprint(T[0]) concatenation运算1234567891011121314# By default, it concatenates along the first axis (concatenates rows)# 行连接x_1 = torch.randn(2, 5) #2行5列y_1 = torch.randn(3, 5) #3行5列z_1 = torch.cat([x_1, y_1])print(z_1) #5行5列# Concatenate columns:# 列连接x_2 = torch.randn(2, 3) #2行3列y_2 = torch.randn(2, 5) #2行5列# second arg specifies which axis to concat alongz_2 = torch.cat([x_2, y_2], 1)print(z_2) #2行8列 Reshaping Tensors12345x = torch.randn(2, 3, 4) # 2*3*4的随机tensorprint(x)print(x.view(2, 12)) # Reshape to 2 rows, 12 columns# Same as above. If one of the dimensions is -1, its size can be inferredprint(x.view(2, -1)) #如果某一维是-1，它的具体大小会被自动推断而出。 Torch Tensor与 NumPy array的互相转换Converting a Torch Tensor to a NumPy array123456789from __future__ import print_functionimport torcha = torch.ones(5)b = a.numpy()# a变化之后b也会跟着变a.add_(1)print(a)print(b) Converting NumPy Array to Torch Tensor123456import numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a) #a变化之后b也会跟着变print(a)print(b) autograd 自动求导原理1234567891011121314151617181920# Tensor factory methods have a ``requires_grad`` flagx = torch.tensor([1., 2., 3], requires_grad=True)# With requires_grad=True, you can still do all the operations you previously# couldy = torch.tensor([4., 5., 6], requires_grad=True)z = x + yprint(z) # BUT z knows something extra.print(z.grad_fn) #grad_fn=&lt;AddBackward0&gt;s = z.sum()print(s)print(s.grad_fn) #grad_fn=&lt;SumBackward0&gt; # what is the derivative of this sum with respect to the first component of x?# s knows that it was created as a sum of the tensor z. z knows that it was the sum x + y# calling .backward() on any variable will run backprop, starting from it.s.backward()print(x.grad) #tensor([1., 1., 1.]) 脱离自动求导的方法z.detach()该命令将z从计算历史中分离出来。 returns a tensor that shares the same storage as z, but with the computation history forgotten. It doesn’t know anythingabout how it was computed. with torch.no_grad()将需要停止自动求导的代码库放置于with torch.no_grad() 范围内 12345print(x.requires_grad) #Trueprint((x ** 2).requires_grad) #Truewith torch.no_grad(): print((x ** 2).requires_grad) #False Neural networksTraining a Classifier先使用python包将数据导入成numpy array images: Pillow, OpenCV audio: scipy and librosa text: NLTK and SpaCy torchvision包提供了计算机视觉领域 Imagenet, CIFAR10, MNIST等数据集的数据入口。 torchvision.datasets torch.utils.data.DataLoader]]></content>
      <categories>
        <category>notes.deeplearning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>deeplearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy]]></title>
    <url>%2F2018%2F12%2F03%2FNumPy%2F</url>
    <content type="text"><![CDATA[NumPy教程http://www.runoob.com/numpy/numpy-tutorial.html PyTorch的基础。]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipenv安装与使用]]></title>
    <url>%2F2018%2F11%2F30%2Fpipenv%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[pipenv使用 Pipfile 和 Pipfile.lock 来管理和维护项目的依赖包，实现虚拟环境运行，避免了包冲突问题 安装与使用安装 pip3 install pipenv 创建空目录 mkdir myproject cd myproject pipenv install requests 如果运行成功，则生成一个 Pipfile。 安装完Requests，创建一个简单的 main.py1234import requestsresponse = requests.get('https://httpbin.org/ip')print('Your IP is &#123;0&#125;'.format(response.json()['origin'])) 测试运行 pipenv run python main.py 1234567891011pipenv shell 激活虚拟环境 exit退出虚拟环境pipenv graph 查看目前安装的库及其依赖pipenv install django==1.11 安装固定版本模块并加入到Pipfilepipenv install django 安装最新？默认版本模块并加入到Pipfilepipenv install pytest --dev 通过添加 –dev 参数 来区分开发环境pipenv uninstall django 卸载第三方库pipenv uninstall --all 卸载全部包并从Pipfile中移除pipenv --venv 获得虚拟环境路pipenv --py 获取虚拟环境 Python 解释器路径pipenv --site-packages 加载系统 Python包 （默认新创建的虚拟环境不包含第三方包）pipenv lock 产生Pipfile.lock文件（默认会自己产生） 官方文档：https://pipenv.readthedocs.io/en/latest/#pipenv-usage InstallErrorTLS/SSL缺失问题描述 [pipenv.exceptions.InstallError]: [‘pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available.python2版本，import ssl无错误pyton3.6.1， import ssl 显示no moudle named _ssl 解决方法python pip 出现locations that require TLS/SSL异常处理方法: https://blog.csdn.net/zhengcaihua0/article/details/7968199112345678910查看openssl安装包，看是否缺少openssl-devel包 # rpm -aq|grep openssl yum安装openssl-devel # yum install openssl-devel -y 对python3.6进行编译安装cd Python-3.6.1./configure --with-sslmakesudo make install 允许安装的python3使用ssl功能模块,进入python3中，执行import ssl无错误 Locking Failed问题描述：12345678910111213141516171819202122232425262728293031323334353637383940Creating a Pipfile for this project…Installing requests…✔ Installation SucceededPipfile.lock not found, creating…Locking [dev-packages] dependencies…Locking [packages] dependencies…✘ Locking Failed![pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/resolver.py&quot;, line 69, in resolve[pipenv.exceptions.ResolutionFailure]: req_dir=requirements_dir[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 695, in resolve_deps[pipenv.exceptions.ResolutionFailure]: req_dir=req_dir,[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 469, in actually_resolve_deps[pipenv.exceptions.ResolutionFailure]: resolved_tree = resolver.resolve()[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 408, in resolve[pipenv.exceptions.ResolutionFailure]: raise ResolutionFailure(message=str(e))[pipenv.exceptions.ResolutionFailure]: pipenv.exceptions.ResolutionFailure: ERROR: ERROR: Could not find a version that matches requests[pipenv.exceptions.ResolutionFailure]: No versions found[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies. First try clearing your dependency cache with $ pipenv lock --clear, then try the original command again. Alternatively, you can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation. Hint: try $ pipenv lock --pre if it is a pre-release dependency.ERROR: ERROR: Could not find a version that matches requestsNo versions foundWas https://pypi.org/simple reachable?[pipenv.exceptions.ResolutionFailure]: req_dir=requirements_dir[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 695, in resolve_deps[pipenv.exceptions.ResolutionFailure]: req_dir=req_dir,[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 469, in actually_resolve_deps[pipenv.exceptions.ResolutionFailure]: resolved_tree = resolver.resolve()[pipenv.exceptions.ResolutionFailure]: File &quot;/usr/local/lib/python3.6/site-packages/pipenv/utils.py&quot;, line 408, in resolve[pipenv.exceptions.ResolutionFailure]: raise ResolutionFailure(message=str(e))[pipenv.exceptions.ResolutionFailure]: pipenv.exceptions.ResolutionFailure: ERROR: ERROR: Could not find a version that matches requests[pipenv.exceptions.ResolutionFailure]: No versions found[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies. First try clearing your dependency cache with $ pipenv lock --clear, then try the original command again. Alternatively, you can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation. Hint: try $ pipenv lock --pre if it is a pre-release dependency.ERROR: ERROR: Could not find a version that matches requestsNo versions foundWas https://pypi.org/simple reachable? 检查https://pypi.org/simple是否能打开。12pipenv.patched.notpip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=&apos;files.pythonhosted.org&apos;, port=443): Read timed out. 更换国内源 阿里云：http://mirrors.aliyun.com/pypi/simple/ 豆瓣：http://pypi.douban.com/simple/ 清华大学：https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学：https://pypi.mirrors.ustc.edu.cn/simple/ 修改 Pipfile 文件默认源12345查看 Pipfile 的内容： cat Pipfile编辑Pipfile： vim Pifile将url = &quot;https://pypi.org/simple&quot;改为url = &quot;https://pypi.tuna.tsinghua.edu.cn/simple/&quot; 跳过lockpipenv install —skip-lock失效，出现TLS/SSL缺失，解决后TLS/SSL缺失问题后，该问题解决。 pipenv命令在pipenv虚拟环境目录下，输入 pipenv 命令可查看命令的完整用法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Usage: pipenv [OPTIONS] COMMAND [ARGS]...Options: --update Update Pipenv &amp; pip to latest. --where Output project home information. --venv Output virtualenv information. --py Output Python interpreter information. --envs Output Environment Variable options. --rm Remove the virtualenv. --bare Minimal output. --completion Output completion (to be eval&apos;d). --man Display manpage. --three / --two Use Python 3/2 when creating virtualenv. --python TEXT Specify which version of Python virtualenv should use. --site-packages Enable site-packages for the virtualenv. --jumbotron An easter egg, effectively. --version Show the version and exit. -h, --help Show this message and exit.Usage Examples: Create a new project using Python 3.6, specifically: $ pipenv --python 3.6 Install all dependencies for a project (including dev): $ pipenv install --dev Create a lockfile containing pre-releases: $ pipenv lock --pre Show a graph of your installed dependencies: $ pipenv graph Check your installed dependencies for security vulnerabilities: $ pipenv check Install a local setup.py into your virtual environment/Pipfile: $ pipenv install -e .Commands: check Checks for security vulnerabilities and against PEP 508 markers provided in Pipfile. graph Displays currently–installed dependency graph information. install Installs provided packages and adds them to Pipfile, or (if none is given), installs all packages. lock Generates Pipfile.lock. open View a given module in your editor. run Spawns a command installed into the virtualenv. shell Spawns a shell within the virtualenv. uninstall Un-installs a provided package and removes it from Pipfile. update Uninstalls all packages, and re-installs package(s) in [packages] to latest compatible versions. Commands: check 检查安全漏洞 graph 显示当前依赖关系图信息 install 安装虚拟环境或者第三方库 lock 锁定并生成Pipfile.lock文件 open 在编辑器中查看一个库 run 在虚拟环境中运行命令 shell 进入虚拟环境 uninstall 卸载一个库 update 卸载当前所有的包，并安装它们的最新版本]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim指令清单]]></title>
    <url>%2F2018%2F11%2F27%2Fvim%E6%8C%87%E4%BB%A4%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[指令大全：https://blog.csdn.net/feosun/article/details/73196299 启动vim vim 直接启动vim vim filename 打开vim并创建名为filename的文件 打开文件 vim file 打开单个文件 vim file1 file2 file3 … 同时打开多个文件 退出按ESC键 跳到命令模式，然后输入:q（不保存）或者:wq（保存） 退出。 :w 保存文件但不退出vi :w file 将修改另外保存到file中，不退出vi :w! 强制保存，不推出vi :wq 保存文件并退出vi :wq! 强制保存文件，并退出vi :q 不保存文件，退出vi :q! 不保存文件，强制退出vi :e! 放弃所有修改，从上次保存文件开始再编辑命令历史 模式 正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空 INSERT, 插入模式（按i键进入?） 左下角显示–INSERT– VISUAL BLOCK, （按v键进入?） 左下角显示–VISUAL–]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令清单]]></title>
    <url>%2F2018%2F11%2F26%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[文件夹与文件操作创建文件夹 mkdir testpipenv 进入文件夹 cd testpipenv 返回当前目录上一层 cd .. 查看当前所处目录位置 pwd 压缩与解压缩解压 对于.tar结尾的文件 tar -xf all.tar 对于.gz结尾的文件 gzip -d all.gz gunzip all.gz 对于.tgz或.tar.gz结尾的文件 tar -xzf all.tar.gz tar -xzf all.tgz 对于.bz2结尾的文件 bzip2 -d all.bz2 bunzip2 all.bz2 对于tar.bz2结尾的文件 tar -xjf all.tar.bz2 对于.Z结尾的文件 uncompress all.Z 对于.tar.Z结尾的文件 tar -xZf all.tar.z]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniGraffle使用小技巧]]></title>
    <url>%2F2018%2F11%2F14%2FOmniGraffle%E4%BD%BF%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[插入latex公式 option+空格 找到LaTeXiT 在输入框中输入latex公式，选择text，点击latex it！ 将生成的图形拖动到OmniGraffle的版面]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>writing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS系统 服务器环境配置]]></title>
    <url>%2F2018%2F11%2F12%2FCentOS%E7%B3%BB%E7%BB%9F-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[远程连接Mac系统，终端terminal ssh 服务器用户名@ip （如：ssh root@xxx.xxx.xxx.xxx） 输入密码 python3安装开发依赖： # yum -y groupinstall development # yum -y install zlib-devel 安装python： [root@VM_58_11_centos ~]# wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tgz 获取安装包 [root@VM_58_11_centos ~]# tar -zxf Python-3.6.1.tgz 解压缩 [root@VM_58_11_centos ~]# cd Python-3.6.1 定位到文件夹 #查看安装包文件 [root@VM_58_11_centos Python-3.6.1]# ls [root@localhost Python-3.6.1]# ./configure 添加配置 [root@localhost Python-3.6.1]# make 编译源码 [root@localhost Python-3.6.1]# make install 执行安装 xamppxampp安装1234567891011121314# wget http://sourceforge.net/projects/xampp/files/XAMPP%20Linux/5.6.14/xampp-linux-x64-5.6.14-0-installer.run xampp下载# chmod 777 xampp-linux-x64-5.6.14-0-installer.run 赋执行权限# ./xampp-linux-x64-5.6.14-0-installer.run 安装# /opt/lampp/lampp start 启动xampp# /opt/lampp/lampp stop 停止xampp# /opt/lampp/lampp security 设置密码卸载xampp# /opt/lampp/lampp stop# rm -rf /opt/lampp添加开机启动服务sudo ln -s /opt/lampp/lampp /etc/init.d/lamppsudo chkconfig --add lampp 远程连接mysql报错2013 - Lost connection to MySQL server at ‘reading initial communication packet’, system error: 0 未解决 MySQL安装[root@localhost ~]# cd /usr/local/src/ [root@localhost src]# wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm [root@localhost src]# rpm -ivh mysql57-community-release-el7-8.noarch.rpm [root@localhost src]# yum -y install mysql-server 配置my.cnfvim /etc/my.cnf 1234567891011121314151617181920212223242526[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockserver_id = 1expire_logs_days = 3 # Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0 log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 启动mysql服务service mysqld restart 重置密码获取随机产生的密码# grep &quot;password&quot; /var/log/mysqld.log 12[root@VM_32_16_centos ~]# grep &quot;password&quot; /var/log/mysqld.log2018-11-28T07:30:50.436132Z 1 [Note] A temporary password is generated for root@localhost: La2aQvn&amp;M=o- 使用该密码进入数据库 [root@VM_32_16_centos ~]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 5 Server version: 5.7.24 Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. 重置密码前无法操作数据库mysql&gt; show databases; ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. 修改密码密码需为包含大小写，数字及符号的字符串 alter user ‘root’@’localhost’ identified by ‘包含大小写，数字及符号的字符串’; 添加新用户grant all on *.* to &#39;newroot&#39;@&#39;%&#39; identified by &#39;密码&#39; with grant option; @’%’可以任意IP登录，@IP地址则限制只能让指定IP登录 刷新权限 flush privileges; 远程连接2003 - Can&#39;t connect to MySQL server on &#39;XXX.xxx.xxx.xxx&#39; 参考Remote Access MySQL connection error:https://stackoverflow.com/questions/29370829/remote-access-mysql-connection-error?spm=a2c4e.11153940.blogcont614613.12.57664a72R9A5pg 检查tcp[root@VM_32_16_centos ~]# nc -l -p 3306 Ncat: bind to :::3306: Address already in use. QUITTING. 如果没有安装nc，先安装 # yum install nc 检查端口[root@VM_32_16_centos ~]# nc ip地址 3306 Ncat: Connection timed out. If this is not working, this is not a mysql server configuration issue but a network issue, and you must check your router firewall rules.Otherwise, your problem comes from mysql server settings. Check your mysql configuration file for bind-address, and remove them to make mysqld accept clients from any IP address. 防火墙问题。 解决方法（已解决）通过使用SSH通过连接。端口22，用户名密码为使用ssh登陆服务器时的用户名密码，常规里ip为localhost，端口3306，用户名密码为mysql的用户名密码。]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows系统重装系统环境配置清单]]></title>
    <url>%2F2018%2F11%2F12%2FWindows%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[数据库mysql，安装XAMPP，mysql文件夹中的data文件夹直接替换navicat for mysql，免安装版 百度网盘链接：https://pan.baidu.com/s/1GMXLmG5K2uBwT8a-bP_E7A 提取码：xkm5 注册码 NAVH-WK6A-DMVK-DKW3 编辑器Atom跨平台文本编辑器 Pycharm凭.edu邮箱获取1年使用期限的注册码 压缩刻录Bandizip远程连接服务器MobaXterm全功能终端软件 链接：https://pan.baidu.com/s/1jxu1Cr6uXMay3kRqJxqqrQ 提取码：fb1g putty代码版本控制SourceTree拥有可视化界面的Git客户端 免登录，跳过初始注册的方法： 首先，安装完 SourceTree 以后先运行一次，弹出初始化登录页面后退出。 在C:\Users\你的电脑名字\AppData\Local\Atlassian\SourceTree目录下新建一个全名为 accounts.json 的文件 123456789101112131415161718192021222324[ &#123; "$id": "1", "$type": "SourceTree.Api.Host.Identity.Model.IdentityAccount, SourceTree.Api.Host.Identity", "Authenticate": true, "HostInstance": &#123; "$id": "2", "$type": "SourceTree.Host.Atlassianaccount.AtlassianAccountInstance, SourceTree.Host.AtlassianAccount", "Host": &#123; "$id": "3", "$type": "SourceTree.Host.Atlassianaccount.AtlassianAccountHost, SourceTree.Host.AtlassianAccount", "Id": "atlassian account" &#125;, "BaseUrl": "https://id.atlassian.com/" &#125;, "Credentials": &#123; "$id": "4", "$type": "SourceTree.Model.BasicAuthCredentials, SourceTree.Api.Account", "Username": "", "Email": null &#125;, "IsDefault": false &#125;] 重启SourceTree SourceTree通过配置SSH来链接Githubhttps://blog.csdn.net/tengdazhang770960436/article/details/54171911 使用 git bash的生成公私钥：id_rsa、id_rsa.pub $ git config —global user.name “sayarara” $ git config —global user.email “xxx.mail@xxx.com” 生成 SSH 密钥 $ ssh-keygen -t rsa -C “xxx.mail@xxx.com” 按3个回车，密码为空。 设置 SourceTree 的 SSH客户端，工具-&gt;选项 ，选择.ssh 目录下的 id_rsa 添加 ~/.ssh/id_rsa.pub 文件内容到 git 服务器 安装python库失败Microsoft visual c++ 14.0 is required错误安装包地址： 链接：https://pan.baidu.com/s/1Jon9u5V8z7ushkLxIj9Igg 提取码：1i95 成功 sklearn datasketch nltk matplotlib x86_amd64\\cl.exe’ failed with exit status 2安装dedupe出现该错误。未解决。]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[django与MySQL]]></title>
    <url>%2F2018%2F09%2F03%2Fdjango%E4%B8%8EMySQL%2F</url>
    <content type="text"><![CDATA[django2.1新手教程http://www.liujiangblog.com/blog/36/ 数据库同步操作https://www.jianshu.com/p/22aa7cca7ff6 自动生成sql语句django会根据setting.py中指定的数据库自动生成sql语句： python manage.py makemigrations 查看自动生成的sql语句python manage.py sqlmigrate 【appname】 【no】 例：python manage.py sqlmigrate myblog 0001 自动同步到数据库python manage.py migrate bug: MySQL Strict ModeWARNINGS: ?: (mysql.W002) MySQL Strict Mode is not set for database connection &#39;default&#39; HINT: MySQL&#39;s Strict Mode fixes many data integrity problems in MySQL, such as data truncation upon insertion, by escalating warnings into errors. It is strongly recommended y ou activate it. See: https://docs.djangoproject.com/en/2.1/ref/databases/#mysql-sql-mode 解决方法1在settings中，在DATABASES变量定义处下面添加 DATABASES[&#39;OPTIONS&#39;][&#39;init_command&#39;] = &quot;SET sql_mode=&#39;STRICT_TRANS_TABLES&#39;&quot; 解决方法212345678910111213DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'cluster', 'USER':'root', 'PASSWORD':'', 'HOST':'localhost', 'PORT':'3306', 'OPTIONS':&#123; 'init_command':"SET sql_mode='STRICT_TRANS_TABLES'", &#125; &#125;&#125; bug: 无法自动生成表Running migrations: No migrations to apply. solution 第一步： 删除该app名字下的migrations文件(migration文件夹中的000x-initial.py文件，存储了自动生成的sql创表语句)。 第二步： 进入数据库，找到django_migrations的表，删除表中app字段为该app名字的所有记录。 第三步: pycharm的Terminal中执行python manage.py makemigrations python manage.py migrate bug：No module named ‘MySQLdb’solution1用pymysql代替。在项目文件夹下的init.py（settings.py也可以？）添加如下代码即可12import pymysqlpymysql.install_as_MySQLdb() solution2 step1: 安装mysqlclient, MySQLdb的分叉版本，加入了对python3的支持。mysqlclient下载地址：https://www.lfd.uci.edu/~gohlke/pythonlibs/ step2: 下载该文件后在下载文件所在目录运行cmd（或运行cmd后切换到该文件目录下）,执行 pip install mysqlclient]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python安装libsvm]]></title>
    <url>%2F2018%2F07%2F12%2Fpython%E5%AE%89%E8%A3%85libsvm%2F</url>
    <content type="text"><![CDATA[参考 https://blog.csdn.net/rena521/article/details/51187981 从官网下载zip压缩包，在任意目录下解压。libsvm官网 http://www.csie.ntu.edu.tw/~cjlin/libsvm/ 去万能宝库上下载对应版本的.whl文件http://www.lfd.uci.edu/~gohlke/pythonlibs/ LIBSVM, a library for Support Vector Machines. libsvm‑3.22‑cp27‑cp27m‑win32.whl libsvm‑3.22‑cp27‑cp27m‑win_amd64.whl libsvm‑3.22‑cp34‑cp34m‑win32.whl libsvm‑3.22‑cp34‑cp34m‑win_amd64.whl libsvm‑3.22‑cp35‑cp35m‑win32.whl libsvm‑3.22‑cp35‑cp35m‑win_amd64.whl libsvm‑3.22‑cp36‑cp36m‑win32.whl libsvm‑3.22‑cp36‑cp36m‑win_amd64.whl libsvm‑3.22‑cp37‑cp37m‑win32.whl libsvm‑3.22‑cp37‑cp37m‑win_amd64.whl cp后的数字表示python版本，win32为32位机，win_amd64为64位机。这里机器的版本号指安装的python版本号。否则报错 xxx.whl is not supported wheel on this platform 参考解决方法 https://stackoverflow.com/questions/28568070/filename-whl-is-not-supported-wheel-on-this-platform 可能原因： python版本号不对，cp后的数字表示python版本，查看python版本命令：python —version pip版本落后。 更新pip版本命令：python -m pip install —upgrade pip amd64指Python版本而非Windows版本。 查看方法： 运行cmd，命令python -v 运行cmd， 命令python 运行cmd， 命令python。 import platformplatform.architecture() 安装.whl文件命令 pip install ....\libsvm-3.21-cp27-none-win32.whl #..为.whl文件的存放路径 python安装目录下的Lib\site-packages文件夹中，有一个\libsvm-3.21.dist-info文件 复制Lib目录下的libsvm.dll，替换掉step1中解压包中windows目录下的libsvm.dll文件。]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>svm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3字典排序]]></title>
    <url>%2F2018%2F07%2F09%2Fpython3%E5%AD%97%E5%85%B8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[12345678910def sort_dict(dict_words): keys = dict_words.keys() values = dict_words.values() list_one = [(key, val) for key, val in zip(keys, values)] list_sort_value_desc = sorted(list_one, key=lambda x: x[1], reverse=True) # 按照第一个元素（value）降序排列 # list_sort_value_asc = sorted(list_one, key=lambda x: x[1], reverse=False) # 按照第一个元素（value）升序排列 # list_sort_key_desc = sorted(list_one, key=lambda x: x[0], reverse=True) # 按照第0个元素（key）降序排列 # list_sort_key_asc = sorted(list_one, key=lambda x: x[0], reverse=False) # 按照第0个元素（key）升序 return list_sort_value_desc]]></content>
      <categories>
        <category>notes.code</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 csv]]></title>
    <url>%2F2018%2F06%2F24%2Fpython3-csv%2F</url>
    <content type="text"><![CDATA[python3 输入输出csv文件的2种形式1234567891011121314151617181920212223242526272829303132333435363738import csvdef testCSVWriterReader(): with open('csvtest.csv','w',newline='') as cf: cw = csv.writer(cf,delimiter=',') cw.writerow(['aa','bb','cc']) cw.writerow(["aa"]*5+['ff']) cf.close() with open('csvtest.csv','r') as f: cr = csv.reader(f,delimiter=',') for row in cr: print(row) for d in row: print(d,' ') f.close()def testCSVDic(): with open('csv_dict.csv','w') as cf: csvhead = ['id','title'] # write head writer = csv.DictWriter(cf,fieldnames=csvhead) writer.writeheader(); writer.writerow(&#123;'id': '1', 'title': 'aa'&#125;) writer.writerow(&#123;'id': '2', 'title': 'bb'&#125;) with open('csv_dict.csv') as cf: reader = csv.DictReader(cf) for row in reader: print(row['id'],row['title'])print('testing writer and reader for csv file......')testCSVWriterReader()print('testing dic writer and dic reader for csv file..... ')testCSVDic()]]></content>
      <categories>
        <category>notes.code</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实体融合ER工具介绍]]></title>
    <url>%2F2018%2F03%2F26%2F%E5%AE%9E%E4%BD%93%E8%9E%8D%E5%90%88ER%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[DedupeGithub地址：https://github.com/dedupeio/dedupeDedupe，基于python的ER工具包。结合试用机器学习、主动学习等技术在结构化数据集上实现快速去重（de-duplication）和实体识别（entity resolution）。 记录相似性的衡量：string metric，实际采用Affine Gap Distance（Hamming distance的一个变种）。 属性逐步比较。与直接比较整条记录相比，可以为不同属性设置不同权重。比如地址去重任务中，电话号码可能比其他属性更为重要。 主动学习用来学习属性权重：人工标注难以判断的记录对（机器判断匹配可能性在50%附近的2条记录），然后机器重新学习属性权重。 使用多种Blocking技术并组合blocking规则以减少判断次数。包括属性，token，相同3个前缀字符，相同5个前缀字符，相同的7个前缀字符，4-gram，6-gram及倒排索引blocks等。 hierarchical clustering with centroid linkage聚类算法用于将不同的匹配对聚成类以表示一个实体。 LimesGithub地址：https://github.com/dice-group/LIMES为Entity linking设计的框架，支持超大规模级实体链接。 时间优化。Plan技术决定哪些任务优先执行，发现任务之间的中间依赖关系以过滤任务，而非独立执行任务。Plan技术能大量减少执行时间。 支持海量的匹配规则，包括字符串，数值，拓扑及时序相似性矩阵度量及自定义距离计算模型 与暴力方法相比，Limes不会损失任何匹配精度但能显著减少匹配操作的数量。]]></content>
      <categories>
        <category>调研</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>ER</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在matlab使用libsvm]]></title>
    <url>%2F2017%2F12%2F25%2F%E5%9C%A8matlab%E4%BD%BF%E7%94%A8libsvm%2F</url>
    <content type="text"><![CDATA[[heart_scale_label, heart_scale_inst] = libsvmread(&#39;heart_scale&#39;); model = svmtrain(heart_scale_label, heart_scale_inst, &#39;-c 1 -g 0.07 -b 1&#39;); [predict_label, accuracy, prob_estimates] = svmpredict(heart_scale_label, heart_scale_inst, model, &#39;-b 1&#39;); label：n*1 data：n*d]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>svm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在matlab中安装libsvm]]></title>
    <url>%2F2017%2F12%2F23%2F%E5%9C%A8matlab%E4%B8%AD%E5%AE%89%E8%A3%85libsvm%2F</url>
    <content type="text"><![CDATA[参考http://blog.csdn.net/chensheng312/article/details/73195158 问题1: 未找到支持的编译器或 SDK。您可以安装免费提供的 MinGW-w64 C/C++ 编译器；请参阅安装 MinGW-w64 编译器。有关更多选项，请访问http://www.mathworks.com/support/compilers/R2016a/win64.html 解决方案：http://blog.csdn.net/desire121/article/details/60466845 1.新建环境变量 MW_MINGW64_LOC，设置为TDM-GCC-64的安装位置（‘D:\mingw-w64\mingw-w64\x86_64-4.9.2-posix-seh-rt_v3-rev1\mingw64\’）,路径最后不要加bin2.在MATLAB环境下执行setenv(‘MW_MINGW64_LOC’,folder)。folder为TDM-GCC的安装位置，要加单引号；3.重启MATLAB mex -h mex CFLAGS=&quot;\$CFLAGS -std=c99&quot; -largeArrayDims libsvmread.c -v 使用 -v 参数展示详细模式，可以看到需要查找的编译器 问题2: gcc: error: -fexceptions: No such file or directory解决方案：https://github.com/cjlin1/libsvm/issues/55将make.m文件下的所有的CFLAGS都替换成COMPFLAGS]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
      <tags>
        <tag>matlab</tag>
        <tag>svm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫及解析]]></title>
    <url>%2F2017%2F12%2F22%2F%E7%88%AC%E8%99%AB%E5%8F%8A%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[师弟写的爬虫及解析工具temme]]></content>
      <categories>
        <category>notes.tools</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Sparse Autoencoder]]></title>
    <url>%2F2017%2F12%2F17%2FSparse-Autoencoder%2F</url>
    <content type="text"><![CDATA[Tutorial of Unsupervised Feature Learning and Deep Learning by Andrew Ng Neural Networksactivation function: sigmoid function: 值域[0,1]\begin{equation} f(z) = \frac{1}{1+\exp(-z)}\end{equation} 一阶导数为：$f’(z) = f(z)(1-f(z))$ tanh function (hyperbolic tangent) 双曲正切函数: 值域[ − 1,1] \begin{equation} f(z) = \tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\end{equation} 一阶导数为：$f’(z) = 1-(f(z))^2$ Neural Network model input layer $\to$ hidden layer $\to$ output layer 每层的神经元数量不计bias unit（bias unit对应intercept term，y=Wx+b 中的b） 设神经网络有$n_l$层，则图中 input layer （记为$L_1$,3 input units） $\to$ hidden layer ($L_2$,3 hidden units; $L_3$,2 hidden units) $\to$ output layer （记为$L_{n_l}$,2 output units） 第$l$ 层对应的参数为$W^l,b^l$，则 \begin{equation} z^{l+1} = W^l a^l+b^l\end{equation} \begin{equation} a^{l+1} = f(z^{l+1})\end{equation} $a^{l+1}$是一个向量，代表第$l+1$层的activation。其中$a^1$是输入x，$a^{n_l}$为输出y feedforward neural network, the connectivity graph does not have any directed loops or cycles Backpropagation Algorithm反向传播算法从输出层开始，反向计算每个节点的残差，并用这些残差计算代价方程对每一个参数的偏导数。 数学原理 中文译者有给出数学证明 Gradient checking and advanced optimizationAutoencoders and SparsityVisualizing a Trained AutoencoderSparse Autoencoder Notation Summary]]></content>
      <categories>
        <category>notes.deeplearning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Deep Feedforward Networks]]></title>
    <url>%2F2017%2F12%2F17%2FDeep-Feedforward-Networks%2F</url>
    <content type="text"><![CDATA[Deep feedforward networks, 也称 feedforward neural networks, 或 multi-layer perceptrons (MLPs)。 MLP用来近似函数，信息从x，经过中间层计算，最后到y。 如果一个扩展feedforward neural networks，使它包含feedback，则称为recurrent neural networks]]></content>
      <categories>
        <category>notes.deeplearning</category>
      </categories>
      <tags>
        <tag>MLPs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有约束最优化方法(Constrained Optimization)]]></title>
    <url>%2F2017%2F12%2F07%2F%E6%9C%89%E7%BA%A6%E6%9D%9F%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95-Constrained-Optimization%2F</url>
    <content type="text"><![CDATA[unconstrained optimization: maximize or minimize a function $f(x)$ over all possible values of x constrained optimization: find the maximal or minimal value of $f(x)$ for values of x in some set $\mathbb{S}$. 集合$\mathbb{S}$内的点称之为 feasible points 方法： simply to modify gradient descent taking the constraint into account. （ 比如search only over step sizes that yield new x points that are feasible） 构造一个无约束最优化问题使得解能映射回原来的有约束最优化问题。 拉格朗日乘子法和KKT条件参考深入理解拉格朗日乘子法（Lagrange Multiplier) 和KKT条件 拉格朗日乘子法(Lagrange Multiplier)和KKT(Karush-Kuhn-Tucker)条件是求解约束优化问题的重要方法。首先用等式约束和不等式约束来描绘集合$\mathbb{S}$。在有等式约束时使用拉格朗日乘子法，在有不等约束时使用KKT条件（KKT条件是拉格朗日乘子法的泛化）。只有当目标函数为凸函数时，使用这两种方法才保证求得的是最优解。 通常需要求解的最优化问题 无约束优化问题 \min ~ f(x) 有等式约束的优化问题 \begin{align}\min &amp; ~ f(x) \nonumber \\s.t. &amp; ~ h_i(x) = 0, i=1,…,m \label{problem_math}\end{align} 有不等式约束的优化问题\begin{align}\min &amp; ~ f(x) \nonumber \\s.t. &amp; ~ g_i(x) \le 0; i = 1,…,n \nonumber \\&amp; ~ h_j(x) = 0, j=1,…,m \label{problem_math2}\end{align} 优化方法。无约束优化问题Fermat定理，即使用求取f(x)的导数，然后令其为零，可以求得候选最优值，再在这些候选值中验证；如果是凸函数，可以保证是最优解。 有等式约束的优化问题：拉格朗日乘子法拉格朗日乘子法（Lagrange Multiplier) ，即把等式约束$h_i(x)$用一个系数与$f(x)$写为一个式子，称为拉格朗日函数，而系数称为拉格朗日乘子。通过拉格朗日函数对各个变量求导，令其为零，可以求得候选值集合，然后验证求得最优值。 the generalized Lagrangian or generalized Lagrange function is: L(x,\alpha) = f(x) +\sum_{i=1}^m \alpha_i h_i(x)或向量形式 L(x,\alpha) = f(x) + \alpha h(x)这里把$\alpha$和$h(x)$视为向量形式，$\alpha$是横向量，h(x)为列向量 求解方法：对Lagrangian函数分别对$\alpha$ 和 $x$ 求导数，并令导数为0，得到$\alpha$ 和 $x$ \nabla_x L(x,\alpha) = 0 \nabla_\alpha L(x,\alpha) = 0有不等式约束的优化问题：KKT条件引入KKT multipliers，$\alpha$和$\lambda$,其中，$\alpha_i \ne 0$, $\lambda_j \ge 0$向量形式： L(x,\alpha,\lambda) = f(x) + \alpha h(x)+\lambda g(x)KKT条件是说最优值必须满足以下条件： $L(x,\alpha, \lambda)$对x求导为零； $h(x) = 0$ $\lambda g(x) = 0$ 原理推导看拉格朗日乘子法和KKT条件]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无约束最优化方法]]></title>
    <url>%2F2017%2F12%2F07%2F%E6%97%A0%E7%BA%A6%E6%9D%9F%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[unconstrained optimization method. marked. 有时间再整理。 梯度下降法最速下降法(Gradient Descent Method)使用梯度。 牛顿法使用Hessian matrix 拟牛顿法 （Quasi-Newton Methods）不再直接计算hessian矩阵, 而是每一步的时候使用梯度向量更新hessian矩阵的近似 共轭方向法共轭梯度法直接法不需要函数导数信息的方法，通过试算来寻找优化方向。它的优势在于对函数没有可微假设。劣势是收敛速度往往很慢。。 univariate search technique单纯形法]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numerical Computation in deep learning]]></title>
    <url>%2F2017%2F12%2F05%2FNumerical-Computation-in-deep-learning%2F</url>
    <content type="text"><![CDATA[update estimates of the solution via an iterative process (通过迭代过程逐步逼近解，而analytically deriving a formula providing a symbolic expression for the correct solution.) Overflow and Underflowrounding error：数值在计算机中存储时产生精度方面的误差，包含 underflow。 数字接近0 overflow。 数字接近正无穷大或负无穷大。 因此设计函数时要求 be stabilized against underflow and overflow Poor Conditioning输入的微小变化会引起计算结果的剧烈变化，即Poor Conditioning。 考虑$AX=b$，如果系统的解对系数矩阵A或b太敏感，（一般系数矩阵A和b是从实验数据里面估计得到，存在误差），方程组系统就是ill-conditioned。否则就是well-condition系统。 condition number：衡量ill-condition系统的可信度，衡量输入发生微小变化时，输出会发生多大的变化。也就是系统对微小变化的敏感度。 condition number值小（在1附近）：well-conditioned condition number值大（远大于1）：ill-conditioned. 输出结果可靠性不高。 （L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题）。 如果方阵A非奇异，则condition number定义为：\begin{equation} \kappa (A) = ||A|| ||A^{-1}||\end{equation} 如果方阵A奇异，那么A的condition number正无穷大. 设函数$f(x) = A^{-1}x$, 方阵有特征分解。则condition number为：\begin{equation} \kappa (A) = \max_{i,j} |\frac{\lambda_i}{\lambda_j}|\end{equation} 条件数即 the ratio of the magnitude of the largest and smallest eigenvalue. Gradient-Based OptimizationJacobian and Hessian MatricesJacobian矩阵和Hessian矩阵 写得很好。 雅可比矩阵假设$f: R^n \to R^m$是一个从欧式n维空间转换到欧式m维空间的函数. 这个函数$f(x) \in \mathbb{R}^m$由m个实函数组成: $f_1(x_1,…,x_n), …, f_m(x_1,…,x_n)$. 这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵, 这就是所谓的雅可比矩阵： J=[\frac{\partial f}{\partial x_1},...,\frac{\partial f}{\partial x_n}]=\left[ \begin{matrix} \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\ \vdots &\ddots & \vdots \\ \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n} \\ \end{matrix} \right](这个矩阵的第i行是由梯度函数的转置$f_i(i=1,…,m)$表示的) 海森Hessian矩阵the Hessian is the Jacobian of the gradient(我的理解是对雅可比矩阵的某一行再做一次雅可比) 设函数$f(x_1,x_2,…,x_n)$,如果$f$的所有二阶导数都存在, 那么$f$的海森矩阵即： H(f)=\left[ \begin{matrix} \frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2} \\ \end{matrix} \right]Hessian matrix is real and symmetric，we can decompose it into a set of real eigenvalues and an orthogonal basis of eigenvectors. 判断极大值以及极小值二阶导数用于判断函数critical point是否极大值/极小值：（一阶导数$f0(x) = 0$的点为 critical points 或 stationary points） $f’(x) = 0, f’’(x) &gt; 0 $ $x$ 局部最小值 $f’(x) = 0, f’’(x) &lt; 0 $ $x$ 局部最大值 $f’(x) = 0, f’’(x) = 0 $ $x$ may be a saddle point(鞍点), or a part of a flat region. 多维情况下，使用Hessian matrix的特征分解： Hessian is positive definite (all its eigenvalues are positive), the point is a local minimum Hessian is negative definite (all its eigenvalues are negative), the point is a local maximum at least one eigenvalue is positive and at least one eigenvalue is negative, we know that x is a local maximum on one cross section of f but a local minimum on another cross section. (a saddle point) 最优化方法When the Hessian has a poor condition number, gradient descent performs poorly. 使用Hessian matrix to guide the search，最简单的一种是Newton’s method（基于2阶形式的泰勒展开） first-order optimization algorithms：use only the gradient，比如 gradient descent second-order optimization algorithms：use the Hessian matrix，比如 Newton’s method 弱限制条件：限制函数满足Lipschitz continuous or have Lipschitz continuous derivatives. quantify our assumption that a small change in the input made by an algorithm such as gradient descent will have a small change in the output. 强限制条件：Convex optimization. 只能应用于convex functions—functions for which the Hessian is positive semidefinite everywhere. 在deep learning中使用率不高。]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>condition number</tag>
        <tag>Optimization</tag>
        <tag>Jacobian</tag>
        <tag>Hessian</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Information Theory in deep learning]]></title>
    <url>%2F2017%2F12%2F05%2FInformation-Theory-in-deep-learning%2F</url>
    <content type="text"><![CDATA[信息理论的基本概念：learning that an unlikely event has occurred is more informative than learning that a likely event has occurred. 对信息的量化： Likely events should have low information content Less likely events should have higher information content Independent events should have additive information. 事件$\mathbf{x} = x$的 self-information：\begin{equation} I(x) = - \log P(x)\end{equation} base e: nats; base-2: bits or shannons. (information measured in bits is just a rescaling of information measured in nats.) Shannon entropy:the amount of uncertainty in an entire probability distribution:\begin{equation} H(\mathbf{x}) = E[I(x)] = -E[\log P(x)] = - \sum_x P(x) \log P(x)\end{equation} Distributions that are nearly deterministic (where the outcome is nearly certain) have low entropy; (a binary random variable p取0或1时，熵最小) distributions that are closer to uniform have high entropy. (a binary random variable p取0.5时，熵最大) 当随机变量$\mathbf{x}$连续时，Shannon entropy 也称为 differential entropy Kullback-Leibler (KL) divergence也称为 relative entropymeasures the difference between two distributions suppose two separate probability distributions $P (x)$ and $Q(x) $ over the same random variable x The Kullback–Leibler divergence from Q to P,(relative entropy of P with respect to Q.)\begin{equation} D_{KL}(P||Q) = E[\log \frac{P(x)}{Q(x)}] = E[\log P(x) - \log Q(x)] = \sum_x P(x) \log \frac{P(x)}{Q(x)}\end{equation} useful properties of KL divergence non-negative. 可以用来衡量两个分布之间的距离，但不是一个真正的距离函数，因为不满足对称性。存在$D_{KL}(P||Q) \ne D_{KL}(Q||P)$ cross-entropy\begin{equation} H(P,Q)= H(P)+D_{KL}(P||Q)\end{equation} 其中：\begin{equation} H(P) = -E[\log P(x)] = - \sum_x P(x) \log P(x)\end{equation} \begin{equation} H(P,Q) = -E[\log Q(x)] = - \sum_x P(x) \log Q(x)\end{equation}]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>entropy</tag>
        <tag>KL divergence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logistic sigmoid & softplus]]></title>
    <url>%2F2017%2F12%2F04%2Flogistic-sigmoid-softplus%2F</url>
    <content type="text"><![CDATA[logistic sigmoid:\begin{equation} \sigma(x) = \frac{1}{1+\exp(-x)}\end{equation} logistic sigmoid经常用于产生Bernoulli distribution的参数p，因为值域(0,1) softplus function\begin{equation} \varsigma(x) = \log {(1+\exp(x))}\end{equation} softplus function常用语产生正态分布的$\beta$ 或$\sigma$参数，因为值域$(0,\infty)$ Useful Properties of logistic sigmoid and softplus function\begin{equation} \sigma(x) = \frac{\exp(x)}{\exp(x)+\exp(0)}\end{equation} \begin{equation} \frac{d}{dx}\sigma(x) = \sigma(x)(1-\sigma(x))\end{equation} \begin{equation} 1-\sigma(x) = \sigma(-x)\end{equation} \begin{equation} \log \sigma(x) =- \varsigma(-x)\end{equation} \begin{equation} \frac{d}{dx}\varsigma(x) = \sigma(x)\end{equation} \begin{equation} \forall x \in (0,1),\sigma^{-1}(x) = \log {(\frac{x}{1-x})}\end{equation} $\sigma^{-1}(x)$ is called the logit in statistics \begin{equation} \forall x &gt; 0,\varsigma^{-1}(x) = \log {(\exp(x)-1)}\end{equation} \begin{equation} \varsigma(x) = \int_{-\infty}^x \sigma(y)dy\end{equation} \begin{equation} \varsigma(x) - \varsigma(-x)= x\end{equation}]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>Probability &amp; Statistics</tag>
        <tag>sigmoid</tag>
        <tag>softplus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Probability in deep learning]]></title>
    <url>%2F2017%2F12%2F04%2FProbability-in-deep-learning%2F</url>
    <content type="text"><![CDATA[three possible sources of uncertainty Inherent stochasticity(随机性) in the system Incomplete observability. Incomplete modeling. (比如把连续的运行轨迹离散化后回丢失准确位置) Random VariablesA random variable is a variable that can take on different values randomly. Random variables may be discrete or continuous. A discrete random variable is one that has a finite or countably infinite number of states. A continuous random variable is associated with a real value. Probability DistributionsA probability distribution is a description of how likely a random variable or set of random variables is to take on each of its possible states. Discrete Variables and Probability Mass Function (PMF)单个随机变量：$\mathbf{x} \sim P(\mathbf{x})$ 随机变量$\mathbf{x}$服从概率分布$P(\mathbf{x})$, $P(\mathbf{x}=x)$多个随机变量：joint probability distribution: $P(\mathbf{x} = x,\mathbf{y} = y)$ 简写为$P(x,y)$ PMF 函数$P$需满足以下性质： The domain of P must be the set of all possible states of $\mathbf{x}$. $\forall x \in \mathbf{x},0 \le P(x) \le 1$ $\sum_{x \in \mathbf{x}} P(x) = 1$ Continuous Variables and Probability Density Functions (PDF)PDF 函数$p$需满足以下性质： The domain of p must be the set of all possible states of $\mathbf{x}$. $\forall x \in \mathbf{x},p(x) \ge 0$ 不要求 $p(x) \le 1$ $\int p(x)dx = 1$ Marginal ProbabilityThe probability distribution over the subset is known as the marginal probability distribution. 如果已知联合概率分布$P(\mathbf{x},\mathbf{y})$则$P(\mathbf{x})$为： \begin{equation} \forall x \in \mathbf{x},P(x) = \sum_y P(\mathbf{x} = x,\mathbf{y} = y)\end{equation} 对于连续变量：\begin{equation} p(x) = \int p(x,y)dy\end{equation} Conditional Probability\begin{equation} P(\mathbf{y} = y | \mathbf{x} = x) = \frac{P(\mathbf{y} = y,\mathbf{x} = x)}{P(\mathbf{x} = x)}\end{equation} 只有$P(\mathbf{x} = x) &gt; 0$时才能计算条件概率。（We cannot compute the conditional probability conditioned on an event that never happens.） The Chain Rule of Conditional Probabilities略 Independence and Conditional IndependenceTwo random variables x and y are independent，记为$\mathbf{x} \perp \mathbf{y}$, if \begin{equation} \forall x \in \mathbf{x}, y \in \mathbf{y}, p(x,y) = p(x)p(y)\end{equation} Two random variables x and y are conditionally independent given a random variable z, 记住为$\mathbf{x} \perp \mathbf{y}|z$\begin{equation} \forall x \in \mathbf{x}, y \in \mathbf{y}, z \in \mathbf{z} ,p(x,y|z) = p(x|z)p(y|z)\end{equation} Expectation, Variance and Covarianceexpectation or expected value设离散随机变量$\mathbf{x}$, 其概率分布为$P(\mathbf{x})$,期望值为： \begin{equation} E[\mathbf{x}] = \sum_x xP(x)\end{equation} \begin{equation} E[f(\mathbf{x})] = \sum_x f(x)P(x)\end{equation} 设连续随机变量$\mathbf{x}$, 期望值为： \begin{equation} E[\mathbf{x}] = \int xp(x)dx\end{equation} \begin{equation} E[f(\mathbf{x})] = \int f(x)p(x)dx\end{equation} variance\begin{equation} Var(\mathbf{x}) = E[(\mathbf{x}-\mu)^2]=E(\mathbf{x}^2)-[E(\mathbf{x})]^2\end{equation} \begin{equation} Var(f(\mathbf{x})) = E[(f(\mathbf{x})-E[f(\mathbf{x})])^2]\end{equation} covariance 协方差\begin{equation} Cov(f(x),g(y)) = E[(f(x)-E[f(x)])(g(y)-E[g(y)])]\end{equation} \begin{equation} Cov(X,Y) = E[(X-\mu_x)(Y-\mu_y)]\end{equation} \begin{equation} Cov(X,Y) = E(XY)-E(X)E(Y)\end{equation} \begin{equation} Cov(X,X) = Var(X)\end{equation} Common Probability DistributionsBernoulli distributionMultinoulli DistributionGaussian distribution / normal distributionExponential and Laplace DistributionsThe Dirac Distribution and Empirical Distribution概率分布只在某个单独点附近有，使用Dirac delta function $\delta (x)$ (是一种generalized function )来定义PDF\begin{equation} p(x) = \delta (x-\mu)\end{equation}The Dirac delta function is defined such that it is zero-valued everywhere except 0, yet integrates to 1 The Dirac delta function as the limit (in the sense of distributions) of the sequence of zero-centered normal distributions Mixtures of DistributionsA latent variable c is a random variable that we cannot observe directly. x 是能观测到的变量。\begin{equation} P(x,c) = P(x|c)P(c)\end{equation} Gaussian mixture model prior probability： 在观测到x之前， the model’s beliefs about c posterior probability：$P(c|x)$, 观测到x之后…. A Gaussian mixture model is a universal approximator of densities, in the sense that any smooth density can be approximated with any specific, non-zero amount of error by a Gaussian mixture model with enough components.（高斯模型混合模型（GMM）理论上可以拟合任意形状的概率分布） Structured Probabilistic Models (graphical models)factorization of a probability distribution with a graph in which each node in the graph corresponds to a random variable, and an edge connecting two random variables means that the probability distribution is able to represent direct interactions between those two random variables. Directed models: 使用directed edges来分解成conditional probability distributions. 假设随机变量（节点）$x_i$的父亲节点集合为$Pa(x_i)$,则随机变量$\mathbf{x}$的概率分布可以分解为\begin{equation} p(\mathbf{x}) = \prod_i p(x_i|Pa(x_i))\end{equation} Undirected models: 使用undirected edges来分解成函数集合。clique $C^i$: any set of nodes that are all connected to each other. 其中$\phi$是与$C^i$有关的函数， Z是normalizing constant ，the sum or integral over all states of the product of the $\phi$ functions \begin{equation} p(\mathbf{x}) = \frac{1}{Z}\prod_i \phi^i (C^i)\end{equation}]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>Probability &amp; Statistics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[norms]]></title>
    <url>%2F2017%2F12%2F01%2Fnorms%2F</url>
    <content type="text"><![CDATA[范数包括向量范数和矩阵范数， 向量范数表征向量空间中向量的大小。 矩阵范数表征矩阵引起变化的大小。 可以把范数当作距离来理解，向量x的范数即从原点到点x的距离。 任意满足以下性质的函数都是norm。(将向量映射到非负值) $f(x)=0 \Rightarrow x = 0$ $f(x+y) \le f(x) + f(y)$ (the triangle inequality) $\forall \alpha \in \mathbb{R},f(\alpha x) = |\alpha|f(x)$ $L^p$ norm对应闵可夫斯基距离(Minkowski Distance)。定义了一组范数。\begin{equation} ||x||= (\sum_i |x_i|^p)^\frac{1}{p}\end{equation} 上图表示了p从无穷到0变化时，三维空间中到原点的距离（范数）为1的点构成的图形的变化情况。 $p=0$ 即L0范数：度量向量中非零元素的个数。不是一个真正的范数。 $0 \le p &lt; 1$时，$L^p$不满足三角不等式。（有些书籍中规定$p \ge 1$） $p=1$ 即L1范数：$||x||$ 为x向量各个元素绝对值之和。 对应曼哈顿距离。 $p=2$ 即L2范数：$||x||$为x向量各个元素平方和的1/2次方。对应欧氏距离。 $p \to \infty$ 即$L^\infty$范数：$||x||$为x向量各个元素绝对值最大那个元素的绝对值，对应切比雪夫距离。 L0范数度量向量中非零元素的个数，在实际情况中，L0的最优问题会被放宽到L1或L2下的最优化。(L1范数是L0范数的最优凸近似?) L1范数向量x中非零元素的绝对值之和。也叫曼哈顿距离、最小绝对误差等。 \begin{equation} ||x||_1= \sum_i |x_i|\end{equation} 使用L1范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference）： \begin{equation} SAD(x_1,x_2)= \sum_i |x_{1i}-x_{2i}|\end{equation} L1范数也被叫做稀疏规则算子（Lasso regularization）。通过L1可以实现特征选择，过滤掉一些没有信息的特征,使模型更有可解释性（Interpretability）。 L2范数\begin{equation} ||x||_2= \sqrt {\sum_i x_i^2}\end{equation} L2也可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）:\begin{equation} SSD(x_1,x_2)= \sum_i (x_{1i}-x_{2i})^2\end{equation}L2范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合（训练误差很小而测试误差很大）的情况，从而提高模型的泛化能力。在回归里面叫“岭回归”（Ridge Regression）。 $L^\infty$范数(max norm)用来度量向量元素的最大值 矩阵范数（Frobenius norm）类似于向量的$L^2$ 范数。\begin{equation} ||A||_F= \sqrt {\sum_{i,j} A_{ij}^2}\end{equation} 向量点乘的范数形式\begin{equation} x^\top y = ||x||_2 ||y||_2 \cos \theta\end{equation} $\theta$是向量x与y之间的夹角。]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>norm</tag>
        <tag>Distance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matrix decomposition in deep learning]]></title>
    <url>%2F2017%2F11%2F30%2Fmatrix-decomposition-in-deep-learning%2F</url>
    <content type="text"><![CDATA[矩阵分解 (decomposition, factorization)是将矩阵拆解为数个矩阵的乘积。(就像可以把整数分解为素数的乘积来研究整数的一些性质) eigendecomposition特征分解（Eigendecomposition），又称谱分解（Spectral decomposition）是将矩阵分解为由其特征值和特征向量表示的矩阵之积的方法。(需要注意只有对可对角化矩阵才可以施以特征分解） N 维非零向量 v 是 N×N 矩阵 A 的特征向量，当且仅当下式成立： \begin{equation} Av = \lambda v\end{equation} 其中$\lambda$ 是一个scalar，特征向量 v 对应的特征值。也即特征向量被施以线性变换 A 只会使向量伸长或缩短而其方向不被改变。（左特征向量也成立：$v^\top A = \lambda v^\top$） 如果v是A的一个特征向量，则v的伸长或缩短 (sv for $ s \in \mathbb{R},s \ne 0$ )仍然是A的特征向量。因此只关注单位特征向量。 假设矩阵A的n个线性独立特征向量（列向量）组成矩阵V，对应的特征值组成列向量$\lambda = [\lambda_1,…,\lambda_n]^\top$. 则A的特征分解为： \begin{equation} A = V \mathbf{ diag}(\lambda) V^{-1}\end{equation} 不是所有的矩阵都能分解成特征值和特征向量，这里我们只关注实对称矩阵（能分解成only real-valued eigenvectors and eigenvalues） \begin{equation} A = Q \Lambda Q^{-1}\end{equation} 其中Q是orthogonal matrix composed of eigenvectors of A, $\Lambda = diag(\lambda)$。由于Q是正交矩阵，可以将A看成是在Q的不同方向(列向量$v^i$)伸缩$\lambda_i$倍。 特征分解的用处： The matrix is singular if and only if any of the eigenvalues are 0. optimize quadratic expressions of the form $f(x)=x^\top Ax $ subject to $||x||_2 =1$. f的最大值是最大的特征值，f的最小值是最小的特征值。 判定矩阵是否正定。 positive semidefinite：eigenvalues are all positive or zero-valued. 半正定矩阵能保证$\forall x,x^\top A x \ge 0$ positive definite：eigenvalues are all positive. 正定矩阵能额外保证 $x^\top A x = 0 \Rightarrow x = 0$ negative definite： all eigenvalues are negative negative semidefinite： all eigenvalues are negative or zero-valued Singular Value Decomposition (SVD分解)奇异值分解（Singular Value Decomposition）将矩阵分解为奇异向量和奇异值（singular vectors and singular values.）,对矩阵的扰动不敏感。 SVD分解比特征分解更通用，任意实数矩阵（即使不是方阵）都有奇异值分解，但特征分解不是。 \begin{equation} A = U D V^\top\end{equation}如果A是$m \times n$矩阵，则U是$m \times m$,D 是 $m \times n$, V 是$n \times n$.U和V是正交矩阵（orthogonal matrices），D是对角矩阵（diagonal matrix），D不一定是方阵。 D中对角线上的元素是矩阵A的奇异值（singular values），矩阵A的非零奇异值是$A^\top A$或$A^\top A$的特征值的平方根。 U中的列向量是左奇异向量（left-singular vectors），左奇异向量是$AA^\top$的特征向量。 V中的列向量是右奇异向量（right-singular vectors），右奇异向量是$A^\top A$的特征向量。 SVD主要用于求矩阵（non-square matrices）的伪逆和主成分分析（PCA）。 matlab code: [U,D,V] = svd(X) SVD分解用于求伪逆 （The Moore-Penrose Pseudoinverse）矩阵A的伪逆定义：\begin{equation} A^+ = \lim_{\alpha \to 0}(A^\top A+ \alpha I)^{-1}A^\top\end{equation} 实际算法更趋于使用下式：\begin{equation} A^+ = VD^+U^\top\end{equation}其中U,D,V是矩阵A的SVD分解。D的伪逆$D^+$是通过把矩阵D主对角线上每个非零元素都求倒数之后再转置得到的。 求伪逆通常可以用来求解线性最小平方、最小二乘法问题。 当矩阵A的列数量多于行数量时，可能存在许多解。用伪逆可以算出其中一个。在所有的答案中，答案$x = A^+y$拥有最小的$L^2$ norm $||x||_2$. 当矩阵A的行数量多于列数量时，可能不存在解。通过伪逆算出来的解会使得$Ax$尽可能接近y，$||Ax-y||_2$最小。]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>matrix</tag>
        <tag>decomposition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linear Algebra in Deep learning]]></title>
    <url>%2F2017%2F11%2F29%2FLinear-Algebra-in-Deep-learning%2F</url>
    <content type="text"><![CDATA[只涉及到与理解deep learning有关的线性代数部分。详细请参考《The Matrix Cookbook》。 Scalars, Vectors, Matrices and Tensors scalars：单纯数字。 $a = a^\top$ Vectors：数字的数组。（只含有一列的矩阵，如无特别说明，所提到的向量都为列向量） Matrices：矩阵。2维数组。$\mathbf{A}_{i,:}$ 矩阵A的第i行， $\mathbf{A}_{:,j}$ 矩阵A的第j列。 Tensors：张量。3维 transpose转置。沿主对角线做镜像翻转。 $(\mathbf{A}^\top)_{ij}=\mathbf{A}_{ji}$ 矩阵乘法 distributive: $A(B+C) = AB+AC$ associative: $A(BC) = (AB)C$ not commutative: $AB = BA$不总是满足。但向量的点乘满足：$x^\top y = y^\top x$ 矩阵乘积的转置: $(AB)^\top = B^\top A^\top$ 线性等式的矩阵形式: $Ax=b$ A矩阵，x：变量，列向量。b：列向量。 Identity and Inverse Matricesidentity matrix: $I_n$, 主对角线上n个元素都为1，其余元素全为0的矩阵。matrix inverse: $A^{-1}A = I_n$ Linear Dependence and Spanspace &amp; subspacespace: 空间内的元素对加法和乘法封闭，即任意的加或者乘，所得的结果仍然属于该空间。subspace：W是线性空间V的一个非空子集，如果 W对于V 中定义的加法和乘法也构成线性空间，那么就成W是V的线性子空间。 span &amp; range设有一个列向量集合$\\{v^1,v^2,…,v^n\\}$linear combination： $\sum_i{c_iv^i}$span: 向量的所有线性组合column space/ range of A：矩阵A中列向量的spannull space: 矩阵A的零空间为 使A中的列向量组合和为零 线性方程组有解的条件$Ax=b$是否有解取决于b是否存在于矩阵A的列空间中。对任意$b \in \mathbb{R}^m$要求有解，要求A的列空间为所有的$\mathbb{R}^m$。如果$\mathbb{R}^m$中存在一个点，在列空间之外，则该点对应的b不存在解。 有解的necessary condition：矩阵A的列数量 $n \ge m$。 m列中可能存在冗余（称为linear dependence）。有解的necessary and sufficient condition：矩阵A中包含m列线性独立的列。the matrix must contain at least one set of m linearly independent columns. 矩阵有逆的条件有唯一解，矩阵为方阵（square，n=m）且m列线性独立。 singular matrix：A square matrix with linearly dependent columns 如果矩阵A不是方阵，或者A是singular矩阵，则不能使用matrix inversion。 Special Kinds of Matrices and VectorsDiagonal matrices主对角线元素非零，其余元素为零的矩阵。对角线上元素相等的对角矩阵称为数量矩阵；对角线上元素全为1的对角矩阵称为单位矩阵。 性质： 和差运算：同阶对角阵的和、差仍是对角阵 数乘运算：数与对角阵的乘积仍为对角阵 乘积运算：同阶对角矩阵的乘积仍为对角阵，且它们的乘积是可交换的，即AB=BA diag(v): a square diagonal matrix whose diagonal entries are given by the entries of the vector v. 对角矩阵的乘法运算非常高效，$diag(v)x=v \odot x$ 只有当主对角线上元素全为非零元素时，对角矩阵的逆存在。$diag(v)^{-1} = diag([1/v_1,…,1/v_n]^\top)$ symmetric matrix\begin{equation} A = A^\top\end{equation} unit vector 单位向量范数为1的向量。$||x||_2 = 1$ orthogonal matrix 正交矩阵当向量x和y满足 $x^\top y = 0$时，x和y垂直。如果向量不但垂直而且范数为1，则称之为orthonormal. orthogonal matrix: a square matrix whose rows are mutually orthonormal and whose columns are mutually orthonormal如果A是正交矩阵 $A^\top 是正交矩阵$ $A^\top A = A A^\top = I$ (I为单位矩阵) A的各行是单位向量且两两正交 A的各列是单位向量且两两正交 $A^{-1} = A^\top$ The Trace Operator （矩阵的迹）矩阵A的迹是矩阵A的主对角线上各个元素的总和。 (迹是所有特征值的和)\begin{equation} Tr(A) = \sum_i A_{ii}\end{equation} 矩阵范数(Frobenius norm)的迹形式：\begin{equation} ||A||_F = \sqrt {Tr(AA^T)}\end{equation} 迹的不变性 （invariant） $Tr(A)=Tr(A^\top)$ invariant to the transpose operator $Tr(ABC) = Tr(CAB) = Tr(BCA)$ $Tr(A_{m \times n}B_{n \times m}) = Tr(B_{n \times m}A_{m \times n})$ $a = Tr(a)$ a scalar is its own trace $Tr(mA+nB)=m Tr(A)+n Tr(B)$ The Determinant 矩阵的行列式det(A)： 方阵A的行列式 The determinant is equal to the product of all the eigenvalues of the matrix. 行列时的性质：https://en.wikipedia.org/wiki/Determinant]]></content>
      <categories>
        <category>notes.math</category>
      </categories>
      <tags>
        <tag>matrix</tag>
        <tag>Linear Algebra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab稀疏矩阵]]></title>
    <url>%2F2017%2F11%2F23%2Fmatlab%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[sparse函数 S=sparse(X) 返回矩阵x的稀疏矩阵形式 S = sparse(I,J,V,m,n,nzmax) 行索引I，列索引J，及对应的值向量V. m和n指定生成的矩阵的维数，nzmax指定为非0元素分配的空间.默认 nzmax = length(I); m = max(I); n = max(J) S = sparse(m,n), 创建全0的稀疏矩阵 full函数X = full(S) 将稀疏矩阵S转化为非稀疏矩阵。 稀疏矩阵的存储使用find函数[I, J, V] = find(A) 返回矩阵A中非零元素的行索引I，列索引J，及对应的值向量V其中矩阵A可以是稀疏矩阵也可以是非稀疏矩阵。]]></content>
      <categories>
        <category>notes.code</category>
      </categories>
      <tags>
        <tag>matrix</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本标注工具]]></title>
    <url>%2F2017%2F11%2F22%2F%E6%96%87%E6%9C%AC%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[IEPYgithub代码地址： https://github.com/machinalis/iepy一个关注关系提取（Relation Extraction）的开源信息提取工具，前端对用户不太友好。 特点： 使用active learning技术。根据用户提供的信息（让用户标注更为重要的样本）来预测剩下的案例，默认分类器为C-Support Vector Classification，可选分类器Stochastic Gradient Descent、Nearest Neighbors、Random Forest、AdaBoost。 对半结构化数据和高准确率要求的案例采用基于规则的关系提取工具。需要用户自定义“regular expression like” rules，一个规则可以认为是一个python函数。 使用Stanford CoreNLP技术来实现共指消解（Coreference resolution is the task of finding all expressions that refer to the same entity in a text，即将文章中所有表述划分为现实世界中不同实体的等价描述） DeepDivegithub代码地址： https://github.com/HazyResearch/mindbender迭代开发知识库的工具mindbender，通过弱监督学习从非结构化的文本中抽取结构化的关系数据，可以判断两个实体间是否存在指定关系。其核心的标注工具是Mindtagger，交互式用户界面十分友好。 当前版本只支持对precision/recall的估计。对于precision估计任务，首先使用SQL查询语句从数据集中找出正相关子集，对系统识别到的实体只让用户判断相关与否，以及增加ad-hoc 标签。 允许用户判断哪些特征能增强预测的表现，这一任务中ad-hoc标签很重要。 其标注结果可以导出成(SQL, CSV/TSV, and JSON) 等格式以作它用，比如作为DeepDive应用的ground truth. bratgithub代码地址： https://github.com/nlplab/brat brat rapid annotation tool(brat)旨在提供一个直觉性质的、快速的方式创造受文本约束的实体和关系标签。 通过选择文本的方式标注（annotate by select text）。 通过拖拉的方式标注关系（connect by drag and drop）。 支持标注命名实体（Named Entity annotation），标注依赖关系（Dependency annotation）,分块（chunking，比如名词词组分块），共指标注（coreference annotation，找出同一实体的不同表述），事件标注（event annotation）等。 支持任意语言的标注。 YEDDAgithub代码地址：https://github.com/jiesutd/SUTDAnnotator一个标注文本、符号和表情中的分块/实体／事件的标注工具，基本支持所有语言。 支持将标注过的文本导出成序列文本。 支持两种标注方式。a，选择文本并在shortcup map中按下相应的标签（标签可自己配置）。b，在文本框中输入（其格式为第几个子串及对应的标签缩写） 推荐系统。两个按钮控制推荐系统的开启与关闭。推荐内容为子串及对应的推荐标签，以不同的颜色在原始文本中标出。并考虑了不能忽视推荐标签错误时的修正时间，设计了针对推荐系统的撤销，调整和删除操作。]]></content>
      <categories>
        <category>调研</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>ER</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch]]></title>
    <url>%2F2017%2F11%2F22%2FElasticsearch%2F</url>
    <content type="text"><![CDATA[什么是ElasticsearchElasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能。 数据存储Elastcisearch 是分布式的文档存储。它能以实时的方式将数据序列化成为json文档来存储。 索引 全文本数据每个字段都设置专用倒排索引 数值与位置数据使用BKD树（A Dynamic Scalable kd-Tree，用来索引多维点数据） Elasticsearch能自动判断field类型并建立合适的索引，也可以定制mapping的方式来设置不同field的索引规则。 Elasticsearch与传统关系型数据库的关系 Elasticsearch 关系型数据库 index DB type table Document row Field column 相似度计算方法默认情况下，返回结果按相关性倒序排列，Elasticsearch 的相似度算法被定义为检索词频率/反向文档频率: 检索词频率 检索词在该字段出现的频率越高，相关性也越高。 反向文档频率 每个检索词在索引中出现的频率越高，相关性越低。检索词出现在多数文档中会比出现在少数文档中的权重更低。 字段长度准则 长度越长，相关性越低。 检索词出现在一个短的 title 要比同样的词出现在一个长的 content 字段权重更大。 单个查询可以联合使用 TF/IDF 和其他方式，比如短语查询中检索词的距离或模糊查询里的检索词相似度。 模糊查询以编辑距离衡量模糊性，查询时使用 fuzziness参数设置最大编辑距离，默认为2。模糊匹配不参与评分，只在有拼写错误时扩大匹配项的范围。 ReferenceElasticsearch: 权威指南]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>索引</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Evaluation of clustering]]></title>
    <url>%2F2017%2F11%2F17%2FEvaluation-of-clustering%2F</url>
    <content type="text"><![CDATA[聚类的目标high intra-cluster similarity and low inter-cluster similarity 数据集有groundtruth时，如何评估聚类结果的优劣？ 4种评估方法 purity。 简单。 NMI。从信息论角度解释。 RI。实质是accuracy，同时惩罚了FP和FN两种错误。 F-measure。为不同的错误类型（FP和FN）赋予不同的权重。 puritypurity取值范围[0，1]，越大越好。 当cluster数量(k)很大时，purity值容易高，极端情况下，当一个类只包含一条记录时，purity取1. \begin{equation} purity(W,C) = \frac {1}{N} \sum_k \max_j |w_k \cap c_j| \label{rij}\end{equation} N为数据集大小，$W=\\{w_1,w_2,…,w_k\\}$ is the set of clusters,即聚类结果。 $C = \\{c_1,c_2,…,c_j\\}$ is the set of classes，即groundtruth. 取$w_k$与$c_j$交集的最大值。 \begin{equation} purity(W,C) = \frac {1}{17} *（5+4+3）\approx 0.71\end{equation} NMI\begin{equation} NMI(W,C) = \frac {I(W,C)}{[H(W)+H(C)]/2}\end{equation} $I(W,C)$衡量类W与groundtruth C之间的互信息。 \begin{align}I(W,C) &amp;= \sum_k \sum_j P(w_k \cap c_j) \log \frac {P(w_k \cap c_j)}{P(w_k)P(c_j)} \nonumber \\&amp;= \sum_k \sum_j \frac{|w_k \cap c_j| }{N} \log \frac {N|w_k \cap c_j| }{|w_k||c_j|} \label{imp}\end{align} 当类与groundtruth之间关系随机时，互信息取0。当类与groundtruth一样时，互信息取1，当类进一步分割成更小的类时，互信息不变。极端情况下，当一个类只包含一条记录时，互信息仍然取1. 因此使用熵来惩罚过大的类数量。（熵随着类数目的增加而增加，极端情况下，当一个类只包含一条记录时，熵取最大值） $H(W)$ 和$H(C)$分布衡量类W与groundtruth C的熵 (entropy). \begin{equation} H(W) = - \sum_k P(w_k) \log P(w_k)\end{equation} $P(w_k)$ 用 cluster $w_k$中的记录在总数据集的出现频率来估算，即$P(w_k)=|w_k|/N$ RI （Rand index） 类型 说明 TP 2个相似实体被分配到了相同类中 TN 2个不相似实体分配到了不同类中 FP 2个不相似实体分配到了相同类中 FN 2个相似实体分配到了不同类中 \begin{equation} RI(W,C) = \frac {TP+TN}{TP+FP+FN+TN}\end{equation} 例子： $TP+FP = C_6^2+C_6^2+C_5^2 = 40$ $TP = C_5^2+C_4^2+C_3^2+C_2^2 = 20$ thus $FP = 40 -20 = 20$ for each classes, $x:8,o:5,\diamondsuit:4$ the number of similar entities: $TP+FN = C_8^2+C_5^2+C_4^2 = 44$ $FN = 44 - 20 = 24$ the number of dissimilar entities : $ TN+FP = 8\times5+8\times 4+5\times4=92$ $TN = 92-20 = 72$ same cluster different clusters same class TP=20 FN=24 different classes FP=20 TN=72 F-measure$Precision = TP/(TP+FP)$ $Recall= TP/(TP+FN)$$F_\beta = \frac{(\beta^2+1)PR}{\beta^2P+R}$ 当$\beta &gt; 1$时，更多的权重给Recall，对FN的惩罚力度更强。 Reference Evaluation of clustering]]></content>
      <categories>
        <category>notes.algorithm</category>
      </categories>
      <tags>
        <tag>Clustering</tag>
        <tag>Evaluation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb]]></title>
    <url>%2F2017%2F11%2F07%2Fmongodb%2F</url>
    <content type="text"><![CDATA[简介MongoDB是NoSQL(Not Only SQL)非关系型数据库中的一种。基本数据单元是文档（document)，可以看成是JSON的扩展--BSON（Binary Serialized Document Format）。集合（collection）是一组（通常建议同种类型）文档，可以看作是一个拥有动态模式(dynamic schema)的表。由于没有预定义模式(predefined schema)，字段的增删／schema的动态变动变得容易，因此最后项目中使用了MongoDB设计存储模块。 工具Robomongo: https://robomongo.org 数据类型支持JSON的所有数据类型：null、布尔、数值、字符串、数组和对象 null 布尔 数值. 默认浮点数，整型值用NumberInt（）或NumberLong（） 字符串 数组. 能作为有序对象(如列表、栈或队列)，也能作为无序对象(如数据集)来操作. 对象. ObjectID() 日期. new Date（） 内嵌文档。被嵌套的文档作为父文档的某个key的值 基本操作insert(),find()/findOne(),update(),remove() 插入 insert()插入一个；batchInsert([])批量插入。 删除。remove()删除所有文档当不删集合和集合元信息；drop()删除集合；remove(条件)删除符合条件的文档。 更新。文档替换。update(criteria, 新文档)。 其中criteria用于定位目标文档。 更新文档中的一部分，对文档中的某些字段进行更新。使用原子性的更新修改器(update modifier)： “$inc”修改器。增加已有键的值，或者该键不存在则创建一个。用于更新分析数据、因果关系、投票或者其他有变化数值的地方. 只能用于整型、长整型或双精度浮点型的值 update(criteria, {“$inc”:{“count”:1}}) 使用”$inc”使count值增加1 “$set”修改器。用来指定一个字段的值。如果这个字段不存在，则创建它。即用于更新模式或者增加用户定义的键 update(criteria,{“$set”:{k,v}}).添加键／更改值。v可以是数组。 update(criteria,{“$unset”:{k,v}}).删除键。 update(criteria,{“$set”:{d.k,v}}). 修改内嵌文档。d是文档中的内嵌文档的key。 数组修改器。 “$push”修改器。如果数组已经存在，会向已有的数组末尾加入一个元素，要是没有就创建一个新的数组。 “$addToSet”修改器。将数组作为集合使用，保证增加元素时数组内的元素不会重复。 “$pop”修改器。数组看成队列或者栈从数组中删除元素。{“$pop”:{“key”:1}}从数组末尾删除一个元素，{“$pop”:{“key”:-1}}则从头部删除。 “$pull”修改器。按特定条件来删除元素。update({},{“$pull”:criteria})。其中criteria用于定位元素。 基于位置（数组下标）的修改器。比如 {“$set”:{“attributes.0.alive”:false}} 基于定位操作符”$”的修改器。”$”用来定位查询文档已经匹配的数组元素，定位符只更新第一个匹配的元素。. update({“attributes.name”:”year”},{“$set”:{“attributes.$.alive”:false}}) upsert更新。要是没有找到符合更新条件的文档，就会以这个条件和更新文档为基础创建一个新的文档。如果找到了匹配的文档，则正常更新。 update(条件文档，修改器文档，true),update的第3个参数表示这是个upsert. save函数。是一个shell函数,如果文档不存在，自动创建文档;如果文档存在，则更新这个文档。它只有一个参数:文档。如果这个文档含有”_id”键，save会调用upsert。否则，调用insert。 更新多个文档。默认只对符合匹配条件的第一个文档执行操作。要更新所有匹配的文档，可以将update的第4个参数设置为true。 findAndModify命令。查询。find查询。 find(). 批量返回集合c中的所有文档 find(doc). find的第一个参数是一个文档，向查询文档中添加键/值对时，即指定查询条件；加入多个键/值对，即组合条件查询。 find(doc,{“key1”:1,”key2”:0}). find的第二个参数指定需要返回的键。1表示返回key1，0表示剔除查询结果中的key2。 查询条件。 比较操作符：”$lt”（小于）、”$lte”（小于等于）、”$gt”（大于）、”$gte”（大于等于）、”$ne”(不等)。 {“age”:{“$gte”:18,”$lte”:30}} 指定查询条件为”age”字段大于等于18、小于等于30的所有文档。 OR查询。 “$in”，对单个键做OR查询。{“num”:{“$in”:[1,2,7]}},条件数组中的值可以是不同类型的数据。 “$nin”, 返回与数组中所有条件都不匹配的文档. “$or”, {“$or”:包含所有可能条件的数组} “$not”,查找与条件不匹配的文档。与正则表达式联合使用时用来查找与特定模式不匹配的文档。 “$and”，“$nor” 特定类型的查询 正则表达式。使用Perl兼容的正则表达式(PCRE)库。 查询数组。 假设有如下文档 {“key”:[“v1”,”v2”,”v3”]} 匹配一个元素。查询条件(实质是一个文档) {“key”:”v2”} 匹配多个元素。“$all”。 查询条件 {“key”,{“$all”:[“v1”,”v2”]}}.返回满足条件（包含值v1和v2）的所有文档。 查询数组特定位置的元素。key.index。 查询条件{“key.2”:”v3”},返回数组第三个元素值为”v3”的所有文档。数组下标是从0开始的。 “$size”，用于查询特定长度的数组。 “$slice”,返回某个键匹配的数组元素的一个子集. findOne(criteria,{“key”:{“$slice”:10}}) 返回前10；findOne(criteria,{“key”:{“$slice”:-10}}) 返回后10条; findOne(criteria,{“key”:{“$slice”:[23,10]}}) 返回第24～33个元素。 $操作符。 find(criteria,{“key.$”:1}) 返回第一个匹配的文档. “$elemMatch”,同时使用查询条件中的各个语句与一个数组元素进行比较。但不会匹配非数组元素。 查询内嵌文档。“$elemMatch”将限定条件进行分组，仅当需要对一个内嵌文档的多个键操作时才会用到。 “$where”，用于在查询中执行任意的JavaScript，在速度上要比常规查询慢很多，应避免使用。 参考文献Mongodb权威指南]]></content>
      <categories>
        <category>notes.database</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据交换格式xml和json]]></title>
    <url>%2F2017%2F11%2F06%2F%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2%E6%A0%BC%E5%BC%8Fxml%E5%92%8Cjson%2F</url>
    <content type="text"><![CDATA[项目中需求使用文本形式存储数据，以应对schema动态变化和实时反馈局部子数据集变化。 以下是对数据交换格式Xml和JSON的调研结果。 Xml和JSON的简单介绍 Xml指可扩展标记语言（Extensible Markup Language），类似于HTML(区别是HTML用来显示数据而Xml用来结构化、存储和传输数据)，需要自定义严格的闭合标签，具有自我描述性。格式统一，跨平台和语言。是标准通用标记语言 (SGML) 的子集，是w3c的推荐标准。 优点：格式统一，符合标准；容易与其他系统进行远程交互，数据共享比较方便。 缺点：XML文件庞大，文件格式复杂，传输占带宽。服务器端和客户端都需要花费大量代码来解析XML。 JSON(JavaScript Object Notation)是一种轻量级的数据交换格式，简洁并且层次结构清晰，结构化标记数据，易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。是基于ECMAScript（w3c制定的js规范）的一个子集，是JS的原生格式。 优点：数据格式简单，易于读写，格式都是压缩的，占用带宽小；适合前端用于开发。 缺点：对数据的描述性比XML差。 Xml和JSON的对比 可读性方面xml好一些，因为有严格闭合的标签。 扩展性方面两者相当。都是易于扩展的跨平台数据交换格式。 编写和解析难度方面，两者都有成熟的工具包提供使用。Xml （dom, SAX, dom4j，JDOM等), json(Gson, JackJson, fastjson等) 数据体积方面，json拥有更小的体积和更快的传输速度，因为xml中包含大量冗余的标记字符。 数据格式对比： Xml提供了逐步解析的方法（SAX），适合于大规模的解析。而JSON只提供整体解析方案。 Xml也提供了整体解析方法（DOM），把一个XML看成一个DOM对象，需要把XML文件整个读入内存。但XML的解析要考虑父节点和子节点，而JSON构建基于key/value，JSON的解析难度要小很多。 索引技术方面： Json索引技术。Mysql5.7及SQL Server 2016开始支持json数据格式，通过创建虚拟列（用于返回要用于筛选的值）来创建索引。 XML索引技术。很复杂。 Xml索引技术 结构摘要类索引。将 XML 数据按照路径进行约简,要求只保存 XML 数据中不同的路径,将具有相同路径的节点集合作为约简中该路径的末端节点的内容。那么,在 XML 数据上的路径查询处理,也就能够在约简结构中得到相同的结果节点集合。比如Fix索引。 节点记录类索引。将 XML 数据分解为数据单元的记录集合,同时在记录中保存该单元在 XML 数据中的位置信息. 节点序号方法。设计某种遍历策略（比如标签有向树的先序遍历、后序遍历和基于字符流模型的顺序遍历等）,得到节点的序号（遍历得到由元素组成的序列,节点的标签在序列中就具有唯一的次序）,将序列与某指标集(比如自然数，局部编码和素数等)建立一一映射的关系。比如Xpath索引。 节点路径方法。将所有的路径表达式看成字符串并且将它们按照字典排序，然后将其作为索引项插入到相应的树型索引结构中。树的每个叶子节点都包含一个表示一个路径表达式的字符串，以及一个与该路径表达式结果相对应的id列表。索引记录的基本模式为（数据单元标识，路径信息），核心技术是字符串的模式匹配，基于Trie，Patricia trie， suffix tree等。 比如Fabric索引，VIST索引。 建议建议直接每个类一个文件，文件名是属性的组合，文件里存记录id。检索用正则检索文件名，动态修改某个类的schema时只要重命名对应的文件名，这样处理局部数据也比较容易，不用每次schema修改都重写全部类文档。 如果一定要在Xml和JSON里二选一，推荐JSON，因为比较适合前端用，k/v的存储方式不用考虑属性之间的次序关系，而且mysql支持存储和索引json格式的数据。]]></content>
      <categories>
        <category>调研</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>索引</tag>
      </tags>
  </entry>
</search>
